{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_pos import read_conll\n",
    "import utils.utils as utils\n",
    "import utils.pos_utils as pos_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge(left, right, r):\n",
    "    left_cols = [\"Tag\"] + list(filter(r.match, left.columns))\n",
    "    right_cols = [\"Tag\"] + list(filter(r.match, right.columns))\n",
    "    return pd.merge(left[left_cols], right[right_cols], on=\"Tag\", suffixes=(None, \"_{}\".format(len(left_cols)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_tag_table(dfs):\n",
    "    total = reduce(lambda left, right: multi_merge(left, right, re.compile(\"^Count($|_)\")), dfs)\n",
    "    total[\"Count\"] = total.iloc[:,1:].apply(np.sum, axis=1)\n",
    "    total = total.sort_values(\"Count\", ascending=False).reset_index(drop=True)\n",
    "    total = total.loc[:, [\"Tag\", \"Count\"]]\n",
    "    total[\"Count(%)\"] = total[\"Count\"] / total[\"Count\"].sum() * 100\n",
    "    total[\"Cumulative(%)\"] = total[\"Count(%)\"].cumsum()\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_freq(info, output, lang_to_group):\n",
    "    lang_name = info[\"lang_name\"]\n",
    "    file_path = info[\"file_path\"]\n",
    "    dataset = info[\"dataset\"]\n",
    "    group = lang_to_group[lang_name]\n",
    "    \n",
    "    conll_data = read_conll(file_path)\n",
    "    tags = np.array(conll_data[2]).flatten().sum()\n",
    "    df = pd.DataFrame(list(Counter(tags).items()), columns=[\"Tag\", \"Count\"])\n",
    "    df = df.sort_values(\"Count\", ascending=False).reset_index(drop=True)\n",
    "    df[\"Count(%)\"] = df[\"Count\"] / df[\"Count\"].sum() * 100\n",
    "    df[\"Cumulative(%)\"] = df[\"Count(%)\"].cumsum()\n",
    "    \n",
    "    # Add missing tags\n",
    "    tagset = pos_utils.get_ud_tags()\n",
    "    missing_tags = set(tagset) ^ set(df[\"Tag\"])\n",
    "    missing_data = {col: [100]*len(missing_tags) if \"Cumulative\" in col else [0]*len(missing_tags) for col in df.columns[1:]}\n",
    "    missing_rows = pd.DataFrame({\"Tag\": list(missing_tags), **missing_data},\n",
    "                                index=range(df.shape[0], df.shape[0] + len(missing_tags)))\n",
    "    df = pd.concat([df, missing_rows])\n",
    "    \n",
    "    if lang_name not in output[group].keys():\n",
    "        output[group][lang_name] = {}\n",
    "    output[group][lang_name][dataset] = df\n",
    "    \n",
    "    # Calculate totals if all datasets are done\n",
    "    if len(output[group][lang_name].keys()) == 3:\n",
    "        total = calculate_total_tag_table(output[group][lang_name].values())\n",
    "        output[group][lang_name][\"total\"] = total\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b0a00ffa5c49ee8187dfe58c1935be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=43.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tag_tables = utils.run_through_data(\"../data/ud/\", tag_freq, lang_to_group=utils.make_lang_group_dict(),\n",
    "                                    table={x: {} for x in [\"Fusional\", \"Isolating\", \"Agglutinative\", \"Introflexive\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_group_avg_tables(group_tables):\n",
    "    group_avgs = {}\n",
    "    \n",
    "    for dataset in [\"train\", \"dev\", \"test\", \"total\"]:\n",
    "        table = reduce(lambda left, right: multi_merge(left, right, re.compile(\"^Count\\(%\\)\")), \n",
    "                       [group_tables[lang][dataset] for lang in group_tables.keys() if dataset in group_tables[lang].keys()])\n",
    "        table = pd.DataFrame({\"Tag\": table[\"Tag\"],\n",
    "                              \"MeanCount(%)\": table.iloc[:,1:].apply(np.mean, axis=1)})\n",
    "        table = table.sort_values(\"MeanCount(%)\", ascending=False).reset_index(drop=True)\n",
    "        table[\"Cumulative(%)\"] = table[\"MeanCount(%)\"].cumsum()\n",
    "        group_avgs[dataset] = table\n",
    "        \n",
    "    return group_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_to_color = {\n",
    "    \"Fusional\": \"#95c78f\",\n",
    "    \"Isolating\": \"#f79d97\",\n",
    "    \"Agglutinative\": \"#abaff5\",\n",
    "    \"Introflexive\": \"#fffecc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in tag_tables.keys():\n",
    "    writer = pd.ExcelWriter(\"tag_stats/tag_stats_{}.xlsx\".format(group.lower()))\n",
    "    workbook  = writer.book\n",
    "    \n",
    "    # Formats\n",
    "    percentage_format = workbook.add_format({\"num_format\": \"0.00\\%\"})\n",
    "    merge_format = workbook.add_format({\n",
    "        \"bold\": 1,\n",
    "        \"border\": 1,\n",
    "        \"align\": \"center\",\n",
    "        \"fg_color\": group_to_color[group],\n",
    "        \"font_size\": 14\n",
    "    })\n",
    "    \n",
    "    # Sheet for every language\n",
    "    langs = utils.order_table(pd.DataFrame(tag_tables[group].keys(), columns=[\"Language\"])).iloc[:,0].values # Order as usual\n",
    "    \n",
    "    for lang in langs:\n",
    "        if len(tag_tables[group][lang].keys()) > 1:\n",
    "            for i, dataset in enumerate([\"train\", \"dev\", \"test\", \"total\"]):\n",
    "                dcol = tag_tables[group][lang][dataset].shape[1] + 1\n",
    "                tag_tables[group][lang][dataset].to_excel(writer, index=False, sheet_name=lang, \n",
    "                                                          startcol=i * dcol, startrow=1)\n",
    "                worksheet = writer.sheets[lang]\n",
    "                worksheet.merge_range(0, i * dcol, 0, (i + 1) * dcol - 2, dataset.upper(), merge_format)\n",
    "                worksheet.set_column((i * dcol) + 2, (i * dcol) + 3, 15, percentage_format)\n",
    "        else:\n",
    "            i = 0\n",
    "            dataset = list(tag_tables[group][lang].keys())[0]\n",
    "            dcol = tag_tables[group][lang][dataset].shape[1] + 1\n",
    "            tag_tables[group][lang][dataset].to_excel(writer, index=False, sheet_name=lang, startrow=1)\n",
    "            worksheet = writer.sheets[lang]\n",
    "            worksheet.merge_range(0, i * dcol, 0, (i + 1) * dcol - 2, dataset.upper(), merge_format)\n",
    "            worksheet.set_column((i * dcol) + 2, (i * dcol) + 3, 15, percentage_format)\n",
    "            \n",
    "        # Insert plot\n",
    "        worksheet.insert_image(tag_tables[group][lang][dataset].shape[0] + 2, 0,\n",
    "                               \"tag_stats/plots/langs/pos_tags_plot_{}.png\".format(lang.lower()),\n",
    "                               {\"x_scale\": 0.75, \"y_scale\": 0.75})\n",
    "            \n",
    "    # Group average sheet\n",
    "    group_avgs = calculate_group_avg_tables(tag_tables[group])\n",
    "    \n",
    "    for i, dataset in enumerate([\"train\", \"dev\", \"test\", \"total\"]):\n",
    "        dcol = group_avgs[dataset].shape[1] + 1\n",
    "        group_avgs[dataset].to_excel(writer, index=False, sheet_name=group, \n",
    "                                     startcol=i * dcol, startrow=1)\n",
    "        worksheet = writer.sheets[group]\n",
    "        worksheet.merge_range(0, i * dcol, 0, (i + 1) * dcol - 2, dataset.upper(), merge_format)\n",
    "        worksheet.set_column((i * dcol) + 1, (i * dcol) + 2, 15, percentage_format)\n",
    "        \n",
    "    worksheet.set_tab_color(group_to_color[group]) # Special color for group sheet\n",
    "    # Insert plot\n",
    "    worksheet.insert_image(group_avgs[dataset].shape[0] + 2, 0, \n",
    "                           \"tag_stats/plots/groups/pos_tags_plot_{}.png\".format(group.lower()),\n",
    "                           {\"x_scale\": 0.75, \"y_scale\": 0.75})\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_table(lang_tables, n):\n",
    "    def get_tag_order(lang_tables, n):\n",
    "        tag_order = []\n",
    "        for row_tags in zip(*[df.loc[:n, \"Tag\"] for df in lang_tables.values()]):\n",
    "            for tag in np.array(Counter(row_tags).most_common(None))[:,0].tolist():\n",
    "                if tag not in tag_order:\n",
    "                    tag_order.append(tag)     \n",
    "        return tag_order[:n]\n",
    "    \n",
    "    def find_freq_col(table):\n",
    "        r = re.compile(\".*Count\\(%\\)\")\n",
    "        return list(filter(r.match, table.columns))[0]\n",
    "                    \n",
    "    tag_order = get_tag_order(lang_tables, n)\n",
    "    tag_order.append(\"OTHERS\")\n",
    "    plot_table = pd.DataFrame({\"Tag\": tag_order})\n",
    "    freq_col = find_freq_col(list(lang_tables.values())[0])\n",
    "    \n",
    "    if len(lang_tables.keys()) > 1:\n",
    "        datasets = [\"total\", \"test\", \"dev\", \"train\"]\n",
    "    else:\n",
    "        datasets = lang_tables.keys()\n",
    "    for dataset in datasets:\n",
    "        df = lang_tables[dataset]\n",
    "        selected = df.set_index(\"Tag\").loc[tag_order[:-1]]\n",
    "        plot_table[dataset.capitalize()] = [*selected[freq_col], 100 - selected[freq_col].sum()]\n",
    "    \n",
    "    plot_table = plot_table.replace(\"_\", \"MULTI\")\n",
    "    return plot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(table_plot, lang, path):\n",
    "    sns.set()\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.rc('xtick', labelsize=16)\n",
    "    plt.rc('ytick', labelsize=16)\n",
    "    plt.rc(\"axes\", labelsize=16)\n",
    "    \n",
    "    g = table_plot.set_index(\"Tag\").rename(columns={\"Total\": \"TOTAL\"}).T.plot(kind=\"barh\", stacked=True, colormap=\"crest_r\", \n",
    "                                                                              figsize=(18, table_plot.shape[1]), xlim=(0, 100))\n",
    "    for i, row in table_plot.iterrows():\n",
    "        cumulative = table_plot.iloc[:i, 1:].sum().values\n",
    "        current = table_plot.iloc[i, 1:].values\n",
    "        for p, y in zip(row.iloc[1:], range(len(current))):\n",
    "            if row[y+1] != 0:\n",
    "                x = cumulative[y] + current[y] / 2\n",
    "                g.text(x=x, y=y+0.375, s=row[\"Tag\"], fontsize=16, fontstretch=\"condensed\", \n",
    "                       horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "                g.text(x=x, y=y, s=\"{:.1f}%\".format(current[y]), fontsize=16, fontstretch=\"condensed\", \n",
    "                       horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                       bbox=dict(boxstyle=\"round, pad=0.15\",\n",
    "                                 fc=(1, 1, 1, 0.5),\n",
    "                                 ec=\"none\"))\n",
    "    g.set_xticks(range(0, 101, 10))\n",
    "    g.set(xlabel = \"Cumulative Frequency (%)\")\n",
    "    g.legend().remove()\n",
    "    g.set_title(lang, fontsize=28, pad=10, color=\"grey\")\n",
    "    sns.despine(ax=g)\n",
    "    g.figure.savefig(path + \"pos_tags_plot_{}.png\".format(lang.lower()), dpi=400)\n",
    "    plt.close(g.figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff3a3b54a8d4b438f0d44636b8db53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for group in tqdm(tag_tables.keys()):\n",
    "    for lang in tag_tables[group].keys():\n",
    "        table_plot = make_plot_table(tag_tables[group][lang], 5)\n",
    "        make_plot(table_plot, lang, \"tag_stats/plots/langs/\")\n",
    "        \n",
    "    group_tables = calculate_group_avg_tables(tag_tables[group])\n",
    "    table_plot = make_plot_table(group_tables, 5)\n",
    "    make_plot(table_plot, group, \"tag_stats/plots/groups/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
