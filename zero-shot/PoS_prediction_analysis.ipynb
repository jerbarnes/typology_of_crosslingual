{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import TFBertForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_pos import ABSATokenizer, convert_examples_to_tf_dataset, read_conll\n",
    "import utils.utils as utils\n",
    "import utils.pos_utils as pos_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertForTokenClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier', 'dropout_75']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/ud/\"\n",
    "\n",
    "code_dicts = utils.make_lang_code_dicts()\n",
    "code_to_name = code_dicts[\"code_to_name\"]\n",
    "name_to_code = code_dicts[\"name_to_code\"]\n",
    "\n",
    "# Model parameters\n",
    "max_length = 256\n",
    "batch_size = 256\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tagset = [\"O\", \"_\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \n",
    "          \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
    "num_labels = len(tagset)\n",
    "label_map = {label: i for i, label in enumerate(tagset)}\n",
    "\n",
    "# Model creation\n",
    "tokenizer = ABSATokenizer.from_pretrained(model_name)\n",
    "config = transformers.BertConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "model = TFBertForTokenClassification.from_pretrained(model_name,\n",
    "                                                     config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4f162befb945099f138b29d0955853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ar\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f4e088de43449f8bed37a6551de161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 12s 3s/step\n",
      "8/8 [==============================] - 26s 3s/step\n",
      "4/4 [==============================] - 12s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\bg\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba93041a2094cb9bd7544065e02cde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\en\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617d2f1b1ad940978a88914f811bef07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\eu\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cbc3d5ed7045359e95e127827c1588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 27s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\fi\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c15d73d93aa4bcfa9ab76c6fdde4669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\he\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f013756c8b4ab88bc5009d48e4daf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\hr\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0f749ab0fb436a9f7a9be44f8abe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ja\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d1049a36dd4c46973b14ce889657c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ko\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fe74eecfd54486b5909d67274a80e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ru\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffddee31f51d491d80f6b728a6a410d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 19s 5s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\sk\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773e8d802e34413cbf58788dc816c55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\tr\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7f849c2b1b4a5f908f3fb1cb112458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\vi\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4237f1c73074f81ba883aabb1732176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 28s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\zh\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c89c52c958e45f6837204cd421d91fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 27s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 16s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_preds = {}\n",
    "reconstructed_preds = {}\n",
    "full_labels = {}\n",
    "reconstructed_labels = {}\n",
    "data_dicts = [full_preds, reconstructed_preds, full_labels, reconstructed_labels]\n",
    "\n",
    "for weights_filepath in tqdm(glob.glob(\"E:/TFM_CCIL/checkpoints/*/*_pos.hdf5\")):\n",
    "    training_lang = weights_filepath.split(\"\\\\\")[1]\n",
    "    train_lang_name = code_to_name[training_lang]\n",
    "    for d in data_dicts:\n",
    "        d[train_lang_name] = {}\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_weights(weights_filepath)\n",
    "    print(\"\\nUsing weights from\", weights_filepath)\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    for directory in tqdm(os.listdir(data_dir)):\n",
    "        # Load and preprocess\n",
    "        path = os.path.join(data_dir, directory)\n",
    "        test_examples, test_dataset = pos_utils.load_data(path, batch_size, tokenizer, tagset, max_length)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict(test_dataset, steps=np.ceil(len(test_examples) / batch_size), verbose=1)\n",
    "\n",
    "        # Postprocessing\n",
    "        tokens, labels, filtered_preds, logits = pos_utils.filter_padding_tokens(test_examples, preds, label_map, tokenizer)\n",
    "        subword_locations = pos_utils.find_subword_locations(tokens)\n",
    "        new_tokens, new_labels, new_preds = pos_utils.reconstruct_subwords(subword_locations, tokens, labels, \n",
    "                                                                           filtered_preds, logits)\n",
    "        \n",
    "        for d, l in zip(data_dicts, [filtered_preds, new_preds, labels, new_labels]):\n",
    "            d[train_lang_name][code_to_name[directory]] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_group = utils.make_lang_group_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arabic\n",
      "Bulgarian           0.69                0.62                \n",
      "English             0.44                0.45                \n",
      "Basque              2.46                1.80                \n",
      "Croatian            0.25                0.22                \n",
      "Japanese            11.08               11.27               \n",
      "Korean              5.61                4.70                \n",
      "Russian             0.40                0.32                \n",
      "Slovak              0.28                0.21                \n",
      "Thai                1.92                2.22                \n",
      "Vietnamese          0.29                0.28                \n",
      "Chinese             0.37                0.38                \n",
      "\n",
      "\n",
      "Average: 3.67\n",
      "Agglutinative: 6.26\n",
      "Others: 0.77\n",
      "\n",
      "\n",
      "\n",
      "Hebrew\n",
      "Bulgarian           2.35                1.23                \n",
      "English             0.24                0.15                \n",
      "Basque              0.35                0.17                \n",
      "Croatian            1.30                0.75                \n",
      "Japanese            4.65                4.12                \n",
      "Korean              0.42                0.24                \n",
      "Russian             0.95                0.44                \n",
      "Slovak              1.58                0.85                \n",
      "Thai                0.31                0.12                \n",
      "Vietnamese          0.28                0.14                \n",
      "Chinese             4.10                2.97                \n",
      "\n",
      "\n",
      "Average: 3.27\n",
      "Agglutinative: 1.84\n",
      "Others: 1.33\n",
      "\n",
      "\n",
      "\n",
      "Finnish\n",
      "Bulgarian           0.01                0.01                \n",
      "English             0.02                0.02                \n",
      "Basque              0.00                0.00                \n",
      "Croatian            0.01                0.02                \n",
      "Japanese            0.08                0.07                \n",
      "Korean              0.03                0.03                \n",
      "Russian             0.00                0.00                \n",
      "Slovak              0.00                0.00                \n",
      "Thai                0.10                0.08                \n",
      "Vietnamese          0.05                0.02                \n",
      "Chinese             0.03                0.03                \n",
      "\n",
      "\n",
      "Average: 0.03\n",
      "Agglutinative: 0.04\n",
      "Others: 0.04\n",
      "\n",
      "\n",
      "\n",
      "Turkish\n",
      "Bulgarian           0.07                0.08                \n",
      "English             0.09                0.09                \n",
      "Basque              0.10                0.05                \n",
      "Croatian            0.03                0.04                \n",
      "Japanese            1.07                0.86                \n",
      "Korean              0.09                0.09                \n",
      "Russian             0.05                0.06                \n",
      "Slovak              0.05                0.07                \n",
      "Thai                0.61                1.05                \n",
      "Vietnamese          0.10                0.10                \n",
      "Chinese             1.19                0.67                \n",
      "\n",
      "\n",
      "Average: 0.62\n",
      "Agglutinative: 0.43\n",
      "Others: 0.34\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mw_langs = [\"Arabic\", \"Hebrew\", \"Finnish\", \"Turkish\"]\n",
    "\n",
    "for lang_name in mw_langs:\n",
    "    print(\"\\n\", lang_name, sep=\"\")\n",
    "    agglutinative = []\n",
    "    others = []\n",
    "    for test_lang in full_preds[lang_name].keys():\n",
    "        if test_lang not in mw_langs:\n",
    "            preds = full_preds[lang_name][test_lang]\n",
    "            preds_agg = reconstructed_preds[lang_name][test_lang]\n",
    "            print(\"{:<20}{:<20.2f}{:<20.2f}\".format(test_lang, (np.array(preds) == 1).sum() / len(preds) * 100, \n",
    "                  (np.array(preds_agg) == 1).sum() / len(preds_agg) * 100))\n",
    "            if lang_to_group[test_lang] == \"Agglutinative\":\n",
    "                agglutinative.extend(preds)\n",
    "            else:\n",
    "                others.extend(preds)\n",
    "    print(\"\\n\")\n",
    "    overall = np.array([values for values in full_preds[lang_name].values()]).sum()\n",
    "    print(\"Average: {:.2f}\".format((np.array(overall) == 1).sum() / len(overall) * 100))\n",
    "    print(\"Agglutinative: {:.2f}\".format((np.array(agglutinative) == 1).sum() / len(agglutinative) * 100))\n",
    "    print(\"Others: {:.2f}\".format((np.array(others) == 1).sum() / len(others) * 100))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bulgarian\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " English\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Basque\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Croatian\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Japanese\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Korean\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Russian\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Slovak\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Vietnamese\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n",
      "\n",
      " Chinese\n",
      "Arabic              0.0                 \n",
      "Finnish             0.0                 \n",
      "Hebrew              0.0                 \n",
      "Thai                0.0                 \n",
      "Turkish             0.0                 \n"
     ]
    }
   ],
   "source": [
    "non_mw_langs = [lang for lang in full_preds.keys() if lang not in [\"Arabic\", \"Hebrew\", \"Finnish\", \"Turkish\"]]\n",
    "\n",
    "for lang_name in non_mw_langs:\n",
    "    print(\"\\n\", lang_name)\n",
    "    for test_lang, preds in full_preds[lang_name].items():\n",
    "        if test_lang not in non_mw_langs:\n",
    "            print(\"{:<20}{:<20}\".format(test_lang, (np.array(preds) == 1).sum() / len(preds) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_excel(\"../results/melted_results_pos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MW over non-MW\n",
      "22.80\n",
      "\n",
      "\n",
      "MW over MW\n",
      "21.43\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "non-MW over MW\n",
      "27.01\n",
      "\n",
      "\n",
      "MW over non-MW\n",
      "27.99\n"
     ]
    }
   ],
   "source": [
    "print(\"MW over non-MW\")\n",
    "print(\"{:.2f}\".format(scores[scores[\"Train Language\"].isin(mw_langs) & \\\n",
    "                             scores[\"Test Language\"].isin(non_mw_langs)][\"Transfer\"].mean()))\n",
    "print(\"\\n\")\n",
    "print(\"MW over MW\")\n",
    "print(\"{:.2f}\".format(scores[scores[\"Train Language\"].isin(mw_langs) & \\\n",
    "                             scores[\"Test Language\"].isin(mw_langs) & \\\n",
    "                             (scores[\"Train Language\"] != scores[\"Test Language\"])][\"Transfer\"].mean()))\n",
    "print(\"\\n\")\n",
    "print(\"-\"*50)\n",
    "print(\"non-MW over MW\")\n",
    "print(\"{:.2f}\".format(scores[scores[\"Train Language\"].isin(non_mw_langs) & \\\n",
    "                             scores[\"Test Language\"].isin(mw_langs)][\"Transfer\"].mean()))\n",
    "print(\"\\n\")\n",
    "print(\"MW over non-MW\")\n",
    "print(\"{:.2f}\".format(scores[scores[\"Train Language\"].isin(non_mw_langs) & \\\n",
    "                             scores[\"Test Language\"].isin(non_mw_langs) & \\\n",
    "                             (scores[\"Train Language\"] != scores[\"Test Language\"])][\"Transfer\"].mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
