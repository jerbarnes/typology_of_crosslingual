{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import TFBertForTokenClassification, TFXLMRobertaForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_pos import MBERT_Tokenizer, XLMR_Tokenizer, convert_examples_to_tf_dataset, read_conll\n",
    "import utils.utils as utils\n",
    "import utils.pos_utils as pos_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training language setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with:    Arabic \n",
      "\n",
      "Already evaluated:\n",
      "\n",
      "Not yet evaluated:  Bulgarian  English  Basque  Finnish  Hebrew  Croatian  Japanese  Korean  Russian  Slovak  Turkish  Vietnamese  Chinese\n",
      "Arabic              Bulgarian  English  Basque  Finnish  Hebrew  Croatian  Japanese  Korean  Russian  Slovak  Turkish  Vietnamese  Chinese\n",
      "\n",
      "Still to train:   \n",
      "\n",
      "Cannot train:       Thai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/ud/\"\n",
    "results_path = \"../results/xlm_roberta/results_pos.xlsx\"\n",
    "full_model_name = \"jplu/tf-xlm-roberta-base\"\n",
    "#full_model_name = \"bert-base-multilingual-cased\"\n",
    "model_name = full_model_name.split(\"/\")[-1] # The \"jplu/\" part is problematic\n",
    "\n",
    "code_dicts = utils.make_lang_code_dicts()\n",
    "code_to_name = code_dicts[\"code_to_name\"]\n",
    "name_to_code = code_dicts[\"name_to_code\"]\n",
    "\n",
    "# Look for languages that have PoS weights but are not in the results file\n",
    "file = open(\"../data_exploration/pos_table.txt\", \"r\")\n",
    "all_langs = [line.split(\"&\")[1].strip() for line in file.readlines()]\n",
    "trained_langs = [code_to_name[x.split(\"\\\\\")[1]] for x in glob.glob(\"E:/TFM_CCIL/checkpoints/*/{}_pos.hdf5\".format(model_name))]\n",
    "untrained_langs = []\n",
    "cannot_train_langs = []\n",
    "for lang in all_langs:\n",
    "    # Check if there are train and dev sets available\n",
    "    if (glob.glob(data_dir + name_to_code[lang] + \"/*train.conllu\") and \n",
    "        glob.glob(data_dir + name_to_code[lang] + \"/*dev.conllu\")):\n",
    "        if lang not in trained_langs:\n",
    "            untrained_langs.append(lang)\n",
    "    else:\n",
    "        cannot_train_langs.append(lang)\n",
    "\n",
    "if os.path.isfile(results_path):\n",
    "    results = pd.read_excel(results_path, sheet_name=None)\n",
    "    remaining_langs = [lang for lang in trained_langs if lang not in results[\"Accuracy\"].columns]\n",
    "else:\n",
    "    remaining_langs = trained_langs\n",
    "    \n",
    "evaluated_langs = [lang for lang in trained_langs if lang not in remaining_langs]\n",
    "    \n",
    "if remaining_langs:\n",
    "    training_lang = remaining_langs[0]\n",
    "    print(\"Evaluating with:   \", training_lang, \"\\n\")\n",
    "    training_lang = name_to_code[training_lang]\n",
    "    print(IPython.utils.text.columnize([\"Already evaluated:\"] + evaluated_langs, displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Not yet evaluated:\"] + remaining_langs[1:], displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Still to train:   \"] + untrained_langs, displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Cannot train:     \"] + cannot_train_langs, displaywidth=150))\n",
    "else:\n",
    "    print(\"No languages remaining\", \"\\n\")\n",
    "    print(IPython.utils.text.columnize([\"Already evaluated:\"] + evaluated_langs, displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Still to train:   \"] + untrained_langs, displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Cannot train:     \"] + cannot_train_langs, displaywidth=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaForTokenClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFXLMRobertaForTokenClassification were not initialized from the model checkpoint at jplu/tf-xlm-roberta-base and are newly initialized: ['dropout_38', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights from E:/TFM_CCIL/checkpoints/ar/tf-xlm-roberta-base_pos.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "max_length = 256\n",
    "batch_size = 256\n",
    "tagset = [\"O\", \"_\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \n",
    "          \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
    "num_labels = len(tagset)\n",
    "label_map = {label: i for i, label in enumerate(tagset)}\n",
    "\n",
    "# Model creation and loading weights\n",
    "if model_name.startswith(\"bert\"):\n",
    "    tokenizer = MBERT_Tokenizer.from_pretrained(full_model_name)\n",
    "    config = transformers.BertConfig.from_pretrained(full_model_name, num_labels=num_labels)\n",
    "    model = TFBertForTokenClassification.from_pretrained(full_model_name,\n",
    "                                                         config=config)\n",
    "else:\n",
    "    tokenizer = XLMR_Tokenizer.from_pretrained(full_model_name)\n",
    "    model = TFXLMRobertaForTokenClassification.from_pretrained(full_model_name, num_labels=num_labels)\n",
    "weights_path = \"E:/TFM_CCIL/checkpoints/\" + training_lang + \"/\"\n",
    "weights_filename = model_name + \"_pos.hdf5\"\n",
    "model.load_weights(weights_path + weights_filename)\n",
    "print(\"Using weights from\", weights_path + weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25ee285f4a9455bbee2fdd28e7537ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "8/8 [==============================] - 27s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "5/5 [==============================] - 15s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "5/5 [==============================] - 14s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "4/4 [==============================] - 13s 3s/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_eval = []\n",
    "\n",
    "for directory in tqdm(os.listdir(data_dir)):\n",
    "    # Load and preprocess\n",
    "    path = os.path.join(data_dir, directory)\n",
    "    test_examples, test_dataset = pos_utils.load_data(path, batch_size, tokenizer, tagset, max_length)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(test_dataset, steps=np.ceil(len(test_examples) / batch_size), verbose=1)\n",
    "    \n",
    "    # Postprocessing\n",
    "    tokens, labels, filtered_preds, logits, subword_locations = pos_utils.filter_padding_tokens(test_examples, preds, \n",
    "                                                                                                label_map, tokenizer)\n",
    "    new_tokens, new_labels, new_preds = pos_utils.reconstruct_subwords(subword_locations, tokens, labels, \n",
    "                                                                       filtered_preds, logits)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = (np.array(new_labels) == np.array(new_preds)).mean()\n",
    "    pos_eval.append((directory, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the table for this training language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_eval = np.array(pos_eval, dtype=object)\n",
    "table = pd.DataFrame({\"Language\": pos_eval[:,0],\n",
    "                      \"Accuracy\": pos_eval[:,1]})\n",
    "table[\"Language\"] = table[\"Language\"].apply(lambda x: code_to_name[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder so that language types are grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../data_exploration/pos_table.txt\", \"r\")\n",
    "lang_order = [line.split(\"&\")[1].strip() for line in file.readlines()]\n",
    "table[\"sort\"] = table[\"Language\"].apply(lambda x: lang_order.index(x))\n",
    "table = table.sort_values(by=[\"sort\"]).drop(\"sort\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>0.77086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>0.65968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>0.762129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slovak</td>\n",
       "      <td>0.771032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.762861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>0.460939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>0.616646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thai</td>\n",
       "      <td>0.612445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.683056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basque</td>\n",
       "      <td>0.59945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>0.301457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korean</td>\n",
       "      <td>0.544923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>0.621164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>0.773939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>0.714805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language  Accuracy\n",
       "0    Bulgarian   0.77086\n",
       "1      English   0.65968\n",
       "2      Russian  0.762129\n",
       "3       Slovak  0.771032\n",
       "4     Croatian  0.762861\n",
       "5      Chinese  0.460939\n",
       "6   Vietnamese  0.616646\n",
       "7         Thai  0.612445\n",
       "8      Finnish  0.683056\n",
       "9       Basque   0.59945\n",
       "10    Japanese  0.301457\n",
       "11      Korean  0.544923\n",
       "12     Turkish  0.621164\n",
       "13      Arabic  0.773939\n",
       "14      Hebrew  0.714805"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update results excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(results_path):\n",
    "    results = pd.read_excel(results_path, sheet_name=None)\n",
    "else:\n",
    "    results = dict.fromkeys(table.columns[1:].values, pd.DataFrame({\"Language\": table[\"Language\"].values}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(results_path) as writer:\n",
    "    full_training_lang = code_to_name[training_lang]\n",
    "    for sheet_name, df in results.items():\n",
    "        # Add each the column for each metric in the corresponding sheet\n",
    "        df[full_training_lang] = table[sheet_name]\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
