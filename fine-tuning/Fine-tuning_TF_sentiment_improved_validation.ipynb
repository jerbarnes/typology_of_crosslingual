{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_sentiment import Example, convert_examples_to_tf_dataset, make_batches\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training language setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No languages remaining\n",
      "Retrain language? y\n",
      "Language to re-train: Hebrew\n"
     ]
    }
   ],
   "source": [
    "code_dicts = utils.make_lang_code_dicts()\n",
    "code_to_name = code_dicts[\"code_to_name\"]\n",
    "name_to_code = code_dicts[\"name_to_code\"]\n",
    "\n",
    "file = open(\"../data_exploration/sentiment_table.txt\", \"r\")\n",
    "all_langs = [line.split(\"&\")[1].strip() for line in file.readlines()]\n",
    "trained_langs = [code_to_name[x.split(\"\\\\\")[1]] for x in glob.glob(\"E:/TFM_CCIL/checkpoints/*/*sentiment.hdf5\")]\n",
    "remaining_langs = [lang for lang in all_langs if lang not in (trained_langs + [\"Turkish\", \"Japanese\", \"Russian\"])]\n",
    "\n",
    "if remaining_langs:\n",
    "    training_lang = remaining_langs[0]\n",
    "    print(\"{:<20}\".format(\"Training language:\"), training_lang, \"\\n\")\n",
    "    training_lang = name_to_code[training_lang]\n",
    "    print(IPython.utils.text.columnize([\"Already trained:   \"] + trained_langs, displaywidth=150))\n",
    "    print(IPython.utils.text.columnize([\"Not yet trained:   \"] + remaining_langs[1:], displaywidth=150))\n",
    "else:\n",
    "    print(\"No languages remaining\")\n",
    "    if input(\"Retrain language? \") == \"y\":\n",
    "        training_lang = input(\"Language to re-train: \")\n",
    "        training_lang = name_to_code[training_lang]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "max_length = 512\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "epochs = 20\n",
    "use_class_weights = True\n",
    "\n",
    "# Model creation\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Checkpoint for best model weights\n",
    "checkpoint_dir = \"E:/TFM_CCIL/checkpoints/\" + training_lang + \"/\"\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Model compilation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e3d109c6624bc1bd6b137b405d23de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8b5367a1c84ccaad1bb95edb4c537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8702.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c99e988c6149ce967ef1b275341934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81067cb2a4a7483188add802f3717cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8702.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{0: 0.6863016863016863, 1: 0.3136983136983137}\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "path = \"../data/sentiment/\"\n",
    "dataset_names = [\"train\", \"dev\", \"train_eval\"]\n",
    "pbar = tqdm(total=4*len(dataset_names))\n",
    "tqdm.pandas()\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # Load and preprocess\n",
    "    if dataset_name == \"train_eval\":\n",
    "        df = pd.read_csv(path + training_lang + \"/\" + \"train\" + \".csv\", header=None)\n",
    "    else:\n",
    "        df = pd.read_csv(path + training_lang + \"/\" + dataset_name + \".csv\", header=None)\n",
    "    df.columns = [\"sentiment\", \"review\"]\n",
    "    df[\"sentiment\"] = pd.to_numeric(df[\"sentiment\"]) # Sometimes label gets read as string\n",
    "    lengths = df[\"review\"].progress_apply(lambda x: len(tokenizer.encode(x)))\n",
    "    df = df[lengths <= max_length].reset_index(drop=True) # Remove long examples\n",
    "    pbar.update(1)\n",
    "    \n",
    "    # Calculate class weights or balance dataset\n",
    "    if use_class_weights and dataset_name == \"train\":\n",
    "        positive_prop = df[\"sentiment\"].mean()\n",
    "        class_weights = {0: positive_prop, 1: 1 - positive_prop}\n",
    "    elif not use_class_weights and dataset_name == \"train\":\n",
    "        class_weights = None\n",
    "        positive_examples = df[\"sentiment\"].sum()\n",
    "        n = min(positive_examples, df.shape[0] - positive_examples)\n",
    "        \n",
    "        if training_lang == \"ar\":\n",
    "            # Testing whether a smaller dataset will work better\n",
    "            n = 5000\n",
    "            \n",
    "        ones_idx = np.random.choice(np.where(df[\"sentiment\"])[0], size=n)\n",
    "        zeros_idx = np.random.choice(np.where(df[\"sentiment\"] == 0)[0], size=n)\n",
    "        df = df.loc[list(ones_idx) + list(zeros_idx)].reset_index(drop=True)\n",
    "    pbar.update(1)\n",
    "        \n",
    "    # Convert to TF dataset\n",
    "    dataset = convert_examples_to_tf_dataset([(Example(text=text, category_index=label)) for label, \n",
    "                                                                                             text in df.values], \n",
    "                                              tokenizer, max_length=max_length)\n",
    "    pbar.update(1)\n",
    "    if dataset_name == \"train\":\n",
    "        dataset, batches = make_batches(dataset, batch_size, repetitions=epochs, shuffle=True)\n",
    "    else:\n",
    "        dataset, batches = make_batches(dataset, 64, repetitions=1, shuffle=False)\n",
    "    \n",
    "    datasets[dataset_name] = (dataset, batches, df)\n",
    "    pbar.update(1)\n",
    "    \n",
    "train_dataset, train_batches, train_df = datasets[\"train\"]\n",
    "dev_dataset, dev_batches, dev_df = datasets[\"dev\"]\n",
    "train_eval_dataset, train_eval_batches, train_eval_df = datasets[\"train_eval\"]\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dev_f1 = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(\"Epoch\", epoch, \"\\n\")\n",
    "    # It's a bit painful to do this but for now it's enough\n",
    "    hist = model.fit(train_dataset, epochs=1, steps_per_epoch=train_batches, class_weight=class_weights)\n",
    "    train_preds = model.predict(train_eval_dataset, steps=train_eval_batches, verbose=1)[0].argmax(axis=-1)\n",
    "    dev_preds = model.predict(dev_dataset, steps=dev_batches, verbose=1)[0].argmax(axis=-1)\n",
    "    \n",
    "    train_f1 = f1_score(train_eval_df[\"sentiment\"].values, train_preds, average=\"macro\")\n",
    "    dev_f1 = f1_score(dev_df[\"sentiment\"].values, dev_preds, average=\"macro\")\n",
    "    print(\"\\nTrain F1:\", train_f1)\n",
    "    print(\"Dev F1:\", dev_f1)\n",
    "    \n",
    "    if dev_f1 > best_dev_f1:\n",
    "        model.save_weights(checkpoint_dir + model_name + \"_sentiment_checkpoint.hdf5\")\n",
    "        print(\"\\nDev F1 improved from\", best_dev_f1, \"to\", dev_f1, \n",
    "              \", saving to \" + checkpoint_dir + model_name + \"_sentiment_checkpoint.hdf5\\n\")\n",
    "        report = classification_report(dev_df[\"sentiment\"].values, dev_preds, output_dict=True)\n",
    "        pd.DataFrame(report).transpose().to_excel(checkpoint_dir + \"checkpoint_report.xlsx\")\n",
    "        best_dev_f1 = dev_f1\n",
    "    else:\n",
    "        print(\"\\nDev F1 did not improve from\", best_dev_f1, \"\\n\", \"-\"*50, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirm weight file overwrite: y\n",
      "Overwriting\n"
     ]
    }
   ],
   "source": [
    "confirm = input(\"Confirm weight file overwrite: \")\n",
    "\n",
    "if confirm == \"y\":\n",
    "    print(\"Overwriting\")\n",
    "    os.replace(checkpoint_dir + model_name + \"_sentiment_checkpoint.hdf5\", \n",
    "               checkpoint_dir + model_name + \"_sentiment.hdf5\")\n",
    "    os.replace(checkpoint_dir + \"checkpoint_report.xlsx\", \n",
    "               checkpoint_dir + \"last_report.xlsx\")\n",
    "else:\n",
    "    print(\"Aborting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
