{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "from conllu import parse\n",
    "import numpy as np\n",
    "from data_preparation_pos import ABSATokenizerSATokenizer, convert_examples_to_tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pos = open(\"../data/ud/en/en_pud-ud-test.conllu\", \"r\", encoding=\"utf-8\").read()\n",
    "sentences = parse(en_pos)\n",
    "tagset = [\"O\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \n",
    "          \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
    "tokenizer = ABSATokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = convert_examples_to_tf_dataset(examples=sentences, tokenizer=tokenizer, tagset=tagset, max_length=512)\n",
    "dataset = dataset.shuffle(100).batch(16).repeat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
       "  array([[  107, 16976, 10271, ...,     0,     0,     0],\n",
       "         [10117, 99603,   130, ...,     0,     0,     0],\n",
       "         [10117, 15824, 20199, ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  138, 41549, 32748, ...,     0,     0,     0],\n",
       "         [12489, 10833,   100, ...,     0,     0,     0],\n",
       "         [24314, 23127, 10189, ...,     0,     0,     0]])>,\n",
       "  'attention_mask': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]])>,\n",
       "  'token_type_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])>},\n",
       " <tf.Tensor: shape=(16, 512), dtype=int64, numpy=\n",
       " array([[13,  5, 11, ...,  0,  0,  0],\n",
       "        [ 6, 12,  9, ...,  0,  0,  0],\n",
       "        [ 6, 12,  1, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 6,  8,  8, ...,  0,  0,  0],\n",
       "        [11, 11,  4, ...,  0,  0,  0],\n",
       "        [ 8, 16, 14, ...,  0,  0,  0]], dtype=int64)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter(dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
