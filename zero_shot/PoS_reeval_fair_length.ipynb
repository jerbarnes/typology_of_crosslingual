{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import TFBertForTokenClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_pos import ABSATokenizer, convert_examples_to_tf_dataset, read_conll\n",
    "import utils.utils as utils\n",
    "import utils.pos_utils as pos_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertForTokenClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['dropout_37', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/ud/\"\n",
    "results_path = \"../results/balanced_length/results_pos_balanced_length.xlsx\"\n",
    "basic_stats = pd.read_excel(\"../data_exploration/pos_basic_stats.xlsx\")\n",
    "en_ref = basic_stats.loc[basic_stats[\"language\"] == \"English\", \"test_avg_tokens\"].values[0]\n",
    "\n",
    "code_dicts = utils.make_lang_code_dicts()\n",
    "code_to_name = code_dicts[\"code_to_name\"]\n",
    "name_to_code = code_dicts[\"name_to_code\"]\n",
    "\n",
    "# Model parameters\n",
    "max_length = 256\n",
    "batch_size = 256\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tagset = [\"O\", \"_\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \n",
    "          \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
    "num_labels = len(tagset)\n",
    "label_map = {label: i for i, label in enumerate(tagset)}\n",
    "\n",
    "# Model creation\n",
    "tokenizer = ABSATokenizer.from_pretrained(model_name)\n",
    "config = transformers.BertConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "model = TFBertForTokenClassification.from_pretrained(model_name,\n",
    "                                                     config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_lengths(test_data, target_mean, tokenizer):\n",
    "    test_examples = [{\"id\": sent_id, \"tokens\": tokens, \"tags\": tags} for sent_id, tokens, tags in zip(test_data[0],\n",
    "                                                                                                      test_data[1],\n",
    "                                                                                                      test_data[2])]\n",
    "    lengths = [len(tokenizer.subword_tokenize(e[\"tokens\"], e[\"tags\"])[0]) for e in test_examples]\n",
    "    df = pd.DataFrame({\"id\": test_data[0], \"length\": lengths})\n",
    "    df = df.sort_values(\"length\").reset_index(drop=True)\n",
    "    \n",
    "    if target_mean < df[\"length\"].mean():\n",
    "        while df[\"length\"].mean() > target_mean:\n",
    "            df = df.drop(df.index[-1])\n",
    "    else:\n",
    "        while df[\"length\"].mean() < target_mean:\n",
    "            df = df.drop(df.index[0])\n",
    "        \n",
    "    lost = len(test_examples) - df.shape[0]\n",
    "    print(\"Examples lost:\", lost)\n",
    "    print(\"Examples remaining:\", df.shape[0])\n",
    "    test_examples = [example for example in test_examples if example[\"id\"] in df[\"id\"].values]\n",
    "    return test_examples, lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_lengths = pd.read_excel(\"../data_exploration/relative_lengths.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc7149d80694f4f8ef659ff8c0c6e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ar\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685353028d354f7dbfbefb6768525d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 285ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\bg\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee0646e557043d8828e9c2920e5b00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 285ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\en\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb43e920a054dbea3252792b43a6815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 286ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\eu\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec21e40eb2740b8995a4487f378fff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 282ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\fi\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f256804158d4ddd9382797179d119f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 284ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\he\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2385bea9be6545a6a0fc53bd046cfb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 285ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\hr\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc442be3388d4b6391c091480153dcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 284ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 976us/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ja\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1092365bf84cee91819943e02b0af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 280ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ko\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb92fdb1dbe495998dbacef400c97a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ru\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bb72d39ae64076a47ea7176a1678e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 283ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\sk\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a72866925246e58dbe7dac64813879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\tr\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a84a39acdcd4457843546424f0e88be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\vi\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68dd8501fb84f2a9f5f5a8d4fe4c771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 283ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\zh\\bert-base-multilingual-cased_pos.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc887b096a8f4f1a80880c399939fd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian\n",
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Slovak\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "3/3 [==============================] - 9s 3s/step\n",
      "Croatian\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "Vietnamese\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Basque\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "6/6 [==============================] - 23s 4s/step\n",
      "Hebrew\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "langs = [\"Bulgarian\", \"Slovak\", \"Croatian\", \"Vietnamese\", \"Basque\", \"Hebrew\"]\n",
    "\n",
    "\n",
    "for weights_filepath in tqdm(glob.glob(\"E:/TFM_CCIL/checkpoints/*/*_pos.hdf5\")):\n",
    "    training_lang = weights_filepath.split(\"\\\\\")[1]\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_weights(weights_filepath)\n",
    "    print(\"\\nUsing weights from\", weights_filepath)\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    pos_eval = []\n",
    "\n",
    "    for directory in tqdm(langs):\n",
    "        print(directory)\n",
    "        directory = name_to_code[directory]\n",
    "        \n",
    "        # Load and preprocess\n",
    "        path = os.path.join(data_dir, directory)\n",
    "        test_data = read_conll(glob.glob(path + \"/*-{}.conllu\".format(\"test\"))[0])\n",
    "        rel_dif = rel_lengths.loc[rel_lengths[\"Language\"] == code_to_name[directory], \n",
    "                                      \"Relative Difference (%)\"].values[0] / 100\n",
    "        target_mean = (1 + rel_dif) * en_ref\n",
    "        test_examples, lost = balance_lengths(test_data, target_mean, tokenizer)\n",
    "        if len(test_examples) == 0 or lost == 0:\n",
    "            continue\n",
    "        test_dataset = pos_utils.convert_examples_to_tf_dataset(examples=test_examples, tokenizer=tokenizer, \n",
    "                                                                tagset=tagset, max_length=256)\n",
    "        test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict(test_dataset, steps=np.ceil(len(test_examples) / batch_size), verbose=1)\n",
    "\n",
    "        # Postprocessing\n",
    "        tokens, labels, filtered_preds, logits = pos_utils.filter_padding_tokens(test_examples, preds, label_map, tokenizer)\n",
    "        subword_locations = pos_utils.find_subword_locations(tokens)\n",
    "        new_tokens, new_labels, new_preds = pos_utils.reconstruct_subwords(subword_locations, tokens, labels, \n",
    "                                                                           filtered_preds, logits)\n",
    "\n",
    "        # Metrics\n",
    "        accuracy = (np.array(new_labels) == np.array(new_preds)).mean()\n",
    "        pos_eval.append((directory, accuracy))\n",
    "        \n",
    "        \n",
    "    # Build table\n",
    "    pos_eval = np.array(pos_eval, dtype=object)\n",
    "    table = pd.DataFrame({\"Language\": pos_eval[:,0],\n",
    "                          \"Accuracy\": pos_eval[:,1]})\n",
    "    table[\"Language\"] = table[\"Language\"].apply(lambda x: code_to_name[x])\n",
    "    file = open(\"../data_exploration/pos_table.txt\", \"r\")\n",
    "    lang_order = [line.split(\"&\")[1].strip() for line in file.readlines()]\n",
    "    table[\"sort\"] = table[\"Language\"].apply(lambda x: lang_order.index(x))\n",
    "    table = table.sort_values(by=[\"sort\"]).drop(\"sort\", axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Update results file\n",
    "    if os.path.isfile(results_path):\n",
    "        results = pd.read_excel(results_path, sheet_name=None)\n",
    "    else:\n",
    "        results = dict.fromkeys(table.columns[1:].values, pd.DataFrame({\"Language\": table[\"Language\"].values}))\n",
    "        \n",
    "    with pd.ExcelWriter(results_path) as writer:\n",
    "        full_training_lang = code_to_name[training_lang]\n",
    "        for sheet_name, df in results.items():\n",
    "            # Add each the column for each metric in the corresponding sheet\n",
    "            df[full_training_lang] = table[sheet_name]\n",
    "            df.to_excel(writer, index=False, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel(results_path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_results = pd.read_excel(\"../results/results_pos.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = {\"Accuracy\": pd.concat([results[\"Accuracy\"], \n",
    "                                     unbalanced_results[\"Accuracy\"].loc[~unbalanced_results[\"Accuracy\"][\"Language\"].isin(\n",
    "                                         results[\"Accuracy\"][\"Language\"].values\n",
    "                                     )]], ignore_index=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>Bulgarian</th>\n",
       "      <th>English</th>\n",
       "      <th>Basque</th>\n",
       "      <th>Finnish</th>\n",
       "      <th>Hebrew</th>\n",
       "      <th>Croatian</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Slovak</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>0.742360</td>\n",
       "      <td>0.989163</td>\n",
       "      <td>0.856586</td>\n",
       "      <td>0.663680</td>\n",
       "      <td>0.765407</td>\n",
       "      <td>0.815187</td>\n",
       "      <td>0.908171</td>\n",
       "      <td>0.657973</td>\n",
       "      <td>0.582978</td>\n",
       "      <td>0.892855</td>\n",
       "      <td>0.879994</td>\n",
       "      <td>0.683766</td>\n",
       "      <td>0.629868</td>\n",
       "      <td>0.616791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slovak</td>\n",
       "      <td>0.749185</td>\n",
       "      <td>0.884192</td>\n",
       "      <td>0.839894</td>\n",
       "      <td>0.725583</td>\n",
       "      <td>0.797534</td>\n",
       "      <td>0.780889</td>\n",
       "      <td>0.940731</td>\n",
       "      <td>0.638573</td>\n",
       "      <td>0.604227</td>\n",
       "      <td>0.883135</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.709555</td>\n",
       "      <td>0.595421</td>\n",
       "      <td>0.599824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.898679</td>\n",
       "      <td>0.844265</td>\n",
       "      <td>0.709327</td>\n",
       "      <td>0.791103</td>\n",
       "      <td>0.776405</td>\n",
       "      <td>0.969353</td>\n",
       "      <td>0.610273</td>\n",
       "      <td>0.589555</td>\n",
       "      <td>0.889766</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.697365</td>\n",
       "      <td>0.587053</td>\n",
       "      <td>0.577125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.589497</td>\n",
       "      <td>0.585018</td>\n",
       "      <td>0.576740</td>\n",
       "      <td>0.558556</td>\n",
       "      <td>0.589225</td>\n",
       "      <td>0.584204</td>\n",
       "      <td>0.553264</td>\n",
       "      <td>0.510788</td>\n",
       "      <td>0.582847</td>\n",
       "      <td>0.578097</td>\n",
       "      <td>0.545664</td>\n",
       "      <td>0.875560</td>\n",
       "      <td>0.549735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basque</td>\n",
       "      <td>0.573987</td>\n",
       "      <td>0.640736</td>\n",
       "      <td>0.699740</td>\n",
       "      <td>0.950939</td>\n",
       "      <td>0.716373</td>\n",
       "      <td>0.692920</td>\n",
       "      <td>0.683152</td>\n",
       "      <td>0.700884</td>\n",
       "      <td>0.631452</td>\n",
       "      <td>0.679808</td>\n",
       "      <td>0.624235</td>\n",
       "      <td>0.675892</td>\n",
       "      <td>0.555815</td>\n",
       "      <td>0.495798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>0.641962</td>\n",
       "      <td>0.594037</td>\n",
       "      <td>0.629980</td>\n",
       "      <td>0.477292</td>\n",
       "      <td>0.527166</td>\n",
       "      <td>0.972137</td>\n",
       "      <td>0.612984</td>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.437448</td>\n",
       "      <td>0.622179</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.509891</td>\n",
       "      <td>0.483422</td>\n",
       "      <td>0.452215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>English</td>\n",
       "      <td>0.610965</td>\n",
       "      <td>0.789626</td>\n",
       "      <td>0.959244</td>\n",
       "      <td>0.591309</td>\n",
       "      <td>0.671063</td>\n",
       "      <td>0.746986</td>\n",
       "      <td>0.732102</td>\n",
       "      <td>0.566378</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.735117</td>\n",
       "      <td>0.712195</td>\n",
       "      <td>0.609081</td>\n",
       "      <td>0.556895</td>\n",
       "      <td>0.510613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.910213</td>\n",
       "      <td>0.847445</td>\n",
       "      <td>0.692359</td>\n",
       "      <td>0.793770</td>\n",
       "      <td>0.795578</td>\n",
       "      <td>0.905512</td>\n",
       "      <td>0.674278</td>\n",
       "      <td>0.652425</td>\n",
       "      <td>0.963269</td>\n",
       "      <td>0.876427</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>0.624425</td>\n",
       "      <td>0.652064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>0.373243</td>\n",
       "      <td>0.563297</td>\n",
       "      <td>0.573477</td>\n",
       "      <td>0.521830</td>\n",
       "      <td>0.532524</td>\n",
       "      <td>0.530376</td>\n",
       "      <td>0.548307</td>\n",
       "      <td>0.560915</td>\n",
       "      <td>0.483166</td>\n",
       "      <td>0.516180</td>\n",
       "      <td>0.491104</td>\n",
       "      <td>0.523185</td>\n",
       "      <td>0.511697</td>\n",
       "      <td>0.919729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thai</td>\n",
       "      <td>0.446455</td>\n",
       "      <td>0.497380</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.465356</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.576029</td>\n",
       "      <td>0.478479</td>\n",
       "      <td>0.454607</td>\n",
       "      <td>0.392126</td>\n",
       "      <td>0.496708</td>\n",
       "      <td>0.446097</td>\n",
       "      <td>0.408295</td>\n",
       "      <td>0.510637</td>\n",
       "      <td>0.491781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>0.805266</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.767696</td>\n",
       "      <td>0.972091</td>\n",
       "      <td>0.794090</td>\n",
       "      <td>0.823641</td>\n",
       "      <td>0.702343</td>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.805140</td>\n",
       "      <td>0.760687</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.567153</td>\n",
       "      <td>0.546631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>0.357696</td>\n",
       "      <td>0.468267</td>\n",
       "      <td>0.485079</td>\n",
       "      <td>0.488561</td>\n",
       "      <td>0.482345</td>\n",
       "      <td>0.537724</td>\n",
       "      <td>0.458082</td>\n",
       "      <td>0.928558</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>0.444303</td>\n",
       "      <td>0.362077</td>\n",
       "      <td>0.544951</td>\n",
       "      <td>0.449994</td>\n",
       "      <td>0.494215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Korean</td>\n",
       "      <td>0.506090</td>\n",
       "      <td>0.581886</td>\n",
       "      <td>0.593705</td>\n",
       "      <td>0.646828</td>\n",
       "      <td>0.655994</td>\n",
       "      <td>0.619814</td>\n",
       "      <td>0.631512</td>\n",
       "      <td>0.544199</td>\n",
       "      <td>0.643150</td>\n",
       "      <td>0.597202</td>\n",
       "      <td>0.524662</td>\n",
       "      <td>0.651170</td>\n",
       "      <td>0.530029</td>\n",
       "      <td>0.536662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>0.588792</td>\n",
       "      <td>0.711609</td>\n",
       "      <td>0.669606</td>\n",
       "      <td>0.663689</td>\n",
       "      <td>0.701456</td>\n",
       "      <td>0.650867</td>\n",
       "      <td>0.724372</td>\n",
       "      <td>0.610547</td>\n",
       "      <td>0.571967</td>\n",
       "      <td>0.663747</td>\n",
       "      <td>0.641643</td>\n",
       "      <td>0.748796</td>\n",
       "      <td>0.508383</td>\n",
       "      <td>0.510472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>0.767047</td>\n",
       "      <td>0.809744</td>\n",
       "      <td>0.734230</td>\n",
       "      <td>0.615874</td>\n",
       "      <td>0.669076</td>\n",
       "      <td>0.760783</td>\n",
       "      <td>0.792974</td>\n",
       "      <td>0.589321</td>\n",
       "      <td>0.535348</td>\n",
       "      <td>0.815816</td>\n",
       "      <td>0.777697</td>\n",
       "      <td>0.626187</td>\n",
       "      <td>0.592357</td>\n",
       "      <td>0.528938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language    Arabic  Bulgarian   English    Basque   Finnish    Hebrew  \\\n",
       "0    Bulgarian  0.742360   0.989163  0.856586  0.663680  0.765407  0.815187   \n",
       "1       Slovak  0.749185   0.884192  0.839894  0.725583  0.797534  0.780889   \n",
       "2     Croatian  0.716129   0.898679  0.844265  0.709327  0.791103  0.776405   \n",
       "3   Vietnamese  0.549600   0.589497  0.585018  0.576740  0.558556  0.589225   \n",
       "4       Basque  0.573987   0.640736  0.699740  0.950939  0.716373  0.692920   \n",
       "5       Hebrew  0.641962   0.594037  0.629980  0.477292  0.527166  0.972137   \n",
       "6      English  0.610965   0.789626  0.959244  0.591309  0.671063  0.746986   \n",
       "7      Russian  0.734463   0.910213  0.847445  0.692359  0.793770  0.795578   \n",
       "8      Chinese  0.373243   0.563297  0.573477  0.521830  0.532524  0.530376   \n",
       "9         Thai  0.446455   0.497380  0.374300  0.465356  0.413580  0.576029   \n",
       "10     Finnish  0.625245   0.805266  0.856917  0.767696  0.972091  0.794090   \n",
       "11    Japanese  0.357696   0.468267  0.485079  0.488561  0.482345  0.537724   \n",
       "12      Korean  0.506090   0.581886  0.593705  0.646828  0.655994  0.619814   \n",
       "13     Turkish  0.588792   0.711609  0.669606  0.663689  0.701456  0.650867   \n",
       "14      Arabic  0.767047   0.809744  0.734230  0.615874  0.669076  0.760783   \n",
       "\n",
       "    Croatian  Japanese    Korean   Russian    Slovak   Turkish  Vietnamese  \\\n",
       "0   0.908171  0.657973  0.582978  0.892855  0.879994  0.683766    0.629868   \n",
       "1   0.940731  0.638573  0.604227  0.883135  0.969881  0.709555    0.595421   \n",
       "2   0.969353  0.610273  0.589555  0.889766  0.890157  0.697365    0.587053   \n",
       "3   0.584204  0.553264  0.510788  0.582847  0.578097  0.545664    0.875560   \n",
       "4   0.683152  0.700884  0.631452  0.679808  0.624235  0.675892    0.555815   \n",
       "5   0.612984  0.480635  0.437448  0.622179  0.570632  0.509891    0.483422   \n",
       "6   0.732102  0.566378  0.539500  0.735117  0.712195  0.609081    0.556895   \n",
       "7   0.905512  0.674278  0.652425  0.963269  0.876427  0.722839    0.624425   \n",
       "8   0.548307  0.560915  0.483166  0.516180  0.491104  0.523185    0.511697   \n",
       "9   0.478479  0.454607  0.392126  0.496708  0.446097  0.408295    0.510637   \n",
       "10  0.823641  0.702343  0.670582  0.805140  0.760687  0.769969    0.567153   \n",
       "11  0.458082  0.928558  0.440559  0.444303  0.362077  0.544951    0.449994   \n",
       "12  0.631512  0.544199  0.643150  0.597202  0.524662  0.651170    0.530029   \n",
       "13  0.724372  0.610547  0.571967  0.663747  0.641643  0.748796    0.508383   \n",
       "14  0.792974  0.589321  0.535348  0.815816  0.777697  0.626187    0.592357   \n",
       "\n",
       "     Chinese  \n",
       "0   0.616791  \n",
       "1   0.599824  \n",
       "2   0.577125  \n",
       "3   0.549735  \n",
       "4   0.495798  \n",
       "5   0.452215  \n",
       "6   0.510613  \n",
       "7   0.652064  \n",
       "8   0.919729  \n",
       "9   0.491781  \n",
       "10  0.546631  \n",
       "11  0.494215  \n",
       "12  0.536662  \n",
       "13  0.510472  \n",
       "14  0.528938  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results[\"Accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(results_path) as writer:\n",
    "        for sheet_name, df in new_results.items():\n",
    "            df.to_excel(writer, index=False, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab7b5377f8408ea868a129649da35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples lost: 299\n",
      "Examples remaining: 817\n",
      "Examples lost: 322\n",
      "Examples remaining: 739\n",
      "Examples lost: 336\n",
      "Examples remaining: 800\n",
      "Examples lost: 514\n",
      "Examples remaining: 286\n",
      "Examples lost: 277\n",
      "Examples remaining: 1522\n",
      "Examples lost: 277\n",
      "Examples remaining: 214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines = []\n",
    "\n",
    "for lang in tqdm(langs):\n",
    "    lang = name_to_code[lang]\n",
    "    \n",
    "    # Load and preprocess\n",
    "    path = os.path.join(data_dir, lang)\n",
    "    test_data = read_conll(glob.glob(path + \"/*-{}.conllu\".format(\"test\"))[0])\n",
    "    rel_dif = rel_lengths.loc[rel_lengths[\"Language\"] == code_to_name[lang], \n",
    "                                  \"Relative Difference (%)\"].values[0] / 100\n",
    "    target_mean = (1 + rel_dif) * en_ref\n",
    "    test_examples, lost = balance_lengths(test_data, target_mean, tokenizer)\n",
    "    \n",
    "    # Metrics\n",
    "    tags = np.array([example[\"tags\"] for example in test_examples]).sum()\n",
    "    acc = tags.count(max(set(tags), key=tags.count)) / len(tags)\n",
    "    baselines.append((code_to_name[lang], acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>0.229535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slovak</td>\n",
       "      <td>0.250462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.254007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>0.333667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basque</td>\n",
       "      <td>0.254235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>0.191697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Accuracy\n",
       "0   Bulgarian  0.229535\n",
       "1      Slovak  0.250462\n",
       "2    Croatian  0.254007\n",
       "3  Vietnamese  0.333667\n",
       "4      Basque  0.254235\n",
       "5      Hebrew  0.191697"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines = pd.DataFrame(np.array(baselines), columns=[\"Language\", \"Accuracy\"])\n",
    "baselines[\"Accuracy\"] = pd.to_numeric(baselines[\"Accuracy\"])\n",
    "baselines = utils.order_table(baselines)\n",
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_baselines = pd.read_excel(\"../results/baselines_pos.xlsx\").rename(columns={\"Baseline\": \"Accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = utils.order_table(pd.concat([baselines, old_baselines[~old_baselines[\"Language\"].isin(langs)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>0.229535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>0.190719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>0.253061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slovak</td>\n",
       "      <td>0.250462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.254007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>0.252627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>0.333667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thai</td>\n",
       "      <td>0.271123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.266890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basque</td>\n",
       "      <td>0.254235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>0.242596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korean</td>\n",
       "      <td>0.487337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>0.370076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>0.268806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>0.191697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language  Accuracy\n",
       "0    Bulgarian  0.229535\n",
       "1      English  0.190719\n",
       "2      Russian  0.253061\n",
       "3       Slovak  0.250462\n",
       "4     Croatian  0.254007\n",
       "5      Chinese  0.252627\n",
       "6   Vietnamese  0.333667\n",
       "7         Thai  0.271123\n",
       "8      Finnish  0.266890\n",
       "9       Basque  0.254235\n",
       "10    Japanese  0.242596\n",
       "11      Korean  0.487337\n",
       "12     Turkish  0.370076\n",
       "13      Arabic  0.268806\n",
       "14      Hebrew  0.191697"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_baselines_path = \"../results/balanced_length/baselines_pos_balanced_length.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(pos_baselines_path) as writer:\n",
    "    for metric in baselines.columns[1:]:\n",
    "        baselines[[\"Language\", metric]].rename(columns={metric: \"Baseline\"}).to_excel(writer, index=False, sheet_name=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
