{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification, BertTokenizer, AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import IPython\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_preparation.data_preparation_sentiment import Example, convert_examples_to_tf_dataset, make_batches\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/sentiment/\"\n",
    "results_path = \"../results/balanced_length/results_sentiment_balanced_length.xlsx\"\n",
    "basic_stats = pd.read_excel(\"../data_exploration/sentiment_basic_stats.xlsx\")\n",
    "en_ref = basic_stats.loc[basic_stats[\"language\"] == \"English\", \"test_avg_tokens\"].values[0]\n",
    "\n",
    "code_dicts = utils.make_lang_code_dicts()\n",
    "code_to_name = code_dicts[\"code_to_name\"]\n",
    "name_to_code = code_dicts[\"name_to_code\"]\n",
    "\n",
    "# Model parameters\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "max_length = 512\n",
    "batch_size = 64\n",
    "\n",
    "# Model creation\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_lengths(test, lengths, target_mean, tokenizer):\n",
    "    test[\"lengths\"] = lengths\n",
    "    test = test.sort_values(\"lengths\")\n",
    "    n = test.shape[0]\n",
    "    \n",
    "    if target_mean < test[\"lengths\"].mean():\n",
    "        while test[\"lengths\"].mean() > target_mean:\n",
    "            test = test.drop(test.index[-1])\n",
    "    else:\n",
    "        while test[\"lengths\"].mean() < target_mean:\n",
    "            test = test.drop(test.index[0])\n",
    "        \n",
    "    lost = n - test.shape[0]\n",
    "    print(\"Examples lost:\", lost)\n",
    "    print(\"Examples remaining:\", test.shape[0])\n",
    "    test = test.drop(\"lengths\", axis=1)\n",
    "    return test, lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_lengths = pd.read_excel(\"../data_exploration/relative_lengths.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b27065b07c47489f9b942686f1db9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ar\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b15715d8e148598ff09c344db20acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 204s 2s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 379ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 39s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\bg\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a212e1b9c81b40cbb2b6cfa85c6156f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 211s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 378ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\en\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184db5454f24442d8f3460bc3ea86924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 387ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\eu\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ad5d1ac0be4afebec9baa31c4b938e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 379ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\fi\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505235308b524fc2bdd0540221171614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 377ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 39s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 118s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\he\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40855db33b240dd928492e60fdb2e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 377ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 5s 2s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\hr\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6c9f011f044d9890a14d0a49ddf1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 211s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 382ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\ko\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68317559a844f9db246136592ee0038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 211s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 383ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\sk\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326061ad26074419ab8b326aa826ef2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 211s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 382ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 118s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\th\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b7f63b4aab477989a80e0b6bb5abed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 380ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\vi\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ab053e1d7d43dca36e81625be865cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 211s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 383ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 90s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 119s 3s/step\n",
      "\n",
      "\n",
      "Using weights from E:/TFM_CCIL/checkpoints\\zh\\bert-base-multilingual-cased_sentiment.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e365bbe476214987b35bd19a60e3babc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "83/83 [==============================] - 210s 3s/step\n",
      "bg\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "en\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "eu\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "2/2 [==============================] - 1s 376ms/step\n",
      "fi\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "he\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "37/37 [==============================] - 93s 3s/step\n",
      "hr\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "5/5 [==============================] - 10s 2s/step\n",
      "ko\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "12/12 [==============================] - 27s 2s/step\n",
      "sk\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "17/17 [==============================] - 40s 2s/step\n",
      "th\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "36/36 [==============================] - 89s 2s/step\n",
      "vi\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "11/11 [==============================] - 25s 2s/step\n",
      "zh\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "47/47 [==============================] - 118s 3s/step\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/sentiment/\"\n",
    "\n",
    "for weights_filepath in tqdm(glob.glob(\"E:/TFM_CCIL/checkpoints/*/*_sentiment.hdf5\")):\n",
    "    training_lang = weights_filepath.split(\"\\\\\")[1]\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_weights(weights_filepath)\n",
    "    print(\"\\nUsing weights from\", weights_filepath)\n",
    "    \n",
    "    # Evaluation\n",
    "    sentiment_eval = []\n",
    "\n",
    "    for lang in tqdm(os.listdir(path)):\n",
    "        if lang not in [\"tr\", \"ja\", \"ru\"]:\n",
    "            print(lang)\n",
    "            \n",
    "            # Load and preprocess\n",
    "            test = pd.read_csv(path + lang + \"/test.csv\", header=None)\n",
    "            test.columns = [\"sentiment\", \"review\"]\n",
    "            lengths = test[\"review\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "            rel_dif = rel_lengths.loc[rel_lengths[\"Language\"] == code_to_name[lang], \n",
    "                                      \"Relative Difference (%)\"].values[0] / 100\n",
    "            target_mean = (1 + rel_dif) * en_ref\n",
    "            test, lost = balance_lengths(test, lengths, target_mean, tokenizer)\n",
    "            if test.shape[0] == 0 or lost == 0:\n",
    "                continue\n",
    "\n",
    "            # Convert to TF dataset\n",
    "            test_dataset = convert_examples_to_tf_dataset([(Example(text=text, category_index=label)) for label, \n",
    "                                                           text in test.values], \n",
    "                                                          tokenizer, max_length=max_length)\n",
    "            test_dataset, test_batches = make_batches(test_dataset, batch_size, repetitions=1, shuffle=False)\n",
    "\n",
    "            # Predict\n",
    "            preds = model.predict(test_dataset, steps=np.ceil(test.shape[0] / batch_size), verbose=1)\n",
    "            clean_preds = preds[0].argmax(axis=-1)\n",
    "\n",
    "            # Metrics\n",
    "            accuracy = accuracy_score(test[\"sentiment\"].values, clean_preds)\n",
    "            precision = precision_score(test[\"sentiment\"].values, clean_preds, average=\"macro\", zero_division=0)\n",
    "            recall = recall_score(test[\"sentiment\"].values, clean_preds, average=\"macro\")\n",
    "            f1 = f1_score(test[\"sentiment\"].values, clean_preds, average=\"macro\")\n",
    "            sentiment_eval.append((lang, accuracy, precision, recall, f1))\n",
    "            \n",
    "    # Build table\n",
    "    sentiment_eval = np.array(sentiment_eval, dtype=object)\n",
    "    table = pd.DataFrame({\"Language\": sentiment_eval[:,0],\n",
    "                          \"Accuracy\": sentiment_eval[:,1],\n",
    "                          \"Macro_Precision\": sentiment_eval[:,2],\n",
    "                          \"Macro_Recall\": sentiment_eval[:,3],\n",
    "                          \"Macro_F1\": sentiment_eval[:,4]})\n",
    "    table[\"Language\"] = table[\"Language\"].apply(lambda x: code_to_name[x])\n",
    "    file = open(\"../data_exploration/sentiment_table.txt\", \"r\")\n",
    "    lang_order = [line.split(\"&\")[1].strip() for line in file.readlines()]\n",
    "    lang_order = [lang for lang in lang_order if lang not in [\"Turkish\", \"Japanese\", \"Russian\"]]\n",
    "    table[\"sort\"] = table[\"Language\"].apply(lambda x: lang_order.index(x))\n",
    "    table = table.sort_values(by=[\"sort\"]).drop(\"sort\", axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Update results file\n",
    "    if os.path.isfile(results_path):\n",
    "        results = pd.read_excel(results_path, sheet_name=None)\n",
    "    else:\n",
    "        results = dict.fromkeys(table.columns[1:].values, pd.DataFrame({\"Language\": table[\"Language\"].values}))\n",
    "    \n",
    "    with pd.ExcelWriter(results_path) as writer:\n",
    "        full_training_lang = code_to_name[training_lang]\n",
    "        for sheet_name, df in results.items():\n",
    "            # Add each the column for each metric in the corresponding sheet\n",
    "            df[full_training_lang] = table[sheet_name]\n",
    "            df.to_excel(writer, index=False, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel(results_path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_results = pd.read_excel(\"../results/results_sentiment.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = {}\n",
    "for sheet_name in results:\n",
    "    new_results[sheet_name] = utils.order_table(pd.concat([results[sheet_name], \n",
    "                                         unbalanced_results[sheet_name].loc[~unbalanced_results[sheet_name][\"Language\"].isin(\n",
    "                                             results[sheet_name][\"Language\"].values\n",
    "                                         )]], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(results_path) as writer:\n",
    "    for sheet_name, df in new_results.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ed99eee00b40da83a674ea414888bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples lost: 4810\n",
      "Examples remaining: 5266\n",
      "Examples lost: 1193\n",
      "Examples remaining: 480\n",
      "Examples lost: 0\n",
      "Examples remaining: 1821\n",
      "Examples lost: 145\n",
      "Examples remaining: 82\n",
      "Examples lost: 245\n",
      "Examples remaining: 152\n",
      "Examples lost: 138\n",
      "Examples remaining: 2354\n",
      "Examples lost: 128\n",
      "Examples remaining: 309\n",
      "Examples lost: 203\n",
      "Examples remaining: 723\n",
      "Examples lost: 23\n",
      "Examples remaining: 1041\n",
      "Examples lost: 70\n",
      "Examples remaining: 2274\n",
      "Examples lost: 7\n",
      "Examples remaining: 678\n",
      "Examples lost: 2523\n",
      "Examples remaining: 2990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines = []\n",
    "\n",
    "for lang in tqdm(os.listdir(path)):\n",
    "    if lang not in [\"tr\", \"ja\", \"ru\"]:\n",
    "        # Load and preprocess\n",
    "        test = pd.read_csv(path + lang + \"/test.csv\", header=None)\n",
    "        test.columns = [\"sentiment\", \"review\"]\n",
    "        lengths = test[\"review\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "        rel_dif = rel_lengths.loc[rel_lengths[\"Language\"] == code_to_name[lang], \n",
    "                                  \"Relative Difference (%)\"].values[0] / 100\n",
    "        target_mean = (1 + rel_dif) * en_ref\n",
    "        test, lost = balance_lengths(test, lengths, target_mean, tokenizer)\n",
    "        \n",
    "        # Metrics\n",
    "        y_true = test[\"sentiment\"].values\n",
    "        y_pred = [test[\"sentiment\"].mode()[0]] * len(y_true)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "        baselines.append((code_to_name[lang], acc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro_Precision</th>\n",
       "      <th>Macro_Recall</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.365625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.422383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>0.500824</td>\n",
       "      <td>0.250412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slovak</td>\n",
       "      <td>0.874159</td>\n",
       "      <td>0.43708</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.466427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.838188</td>\n",
       "      <td>0.419094</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>0.514749</td>\n",
       "      <td>0.257375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.339825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thai</td>\n",
       "      <td>0.599824</td>\n",
       "      <td>0.299912</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.374931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.414474</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.453237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Basque</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.445946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Korean</td>\n",
       "      <td>0.586445</td>\n",
       "      <td>0.293223</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.36966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>0.824155</td>\n",
       "      <td>0.412077</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.451801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>0.705607</td>\n",
       "      <td>0.352804</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.413699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language  Accuracy Macro_Precision Macro_Recall  Macro_F1\n",
       "0    Bulgarian   0.73125        0.365625          0.5  0.422383\n",
       "1      English  0.500824        0.250412          0.5  0.333699\n",
       "2       Slovak  0.874159         0.43708          0.5  0.466427\n",
       "3     Croatian  0.838188        0.419094          0.5  0.455986\n",
       "4      Chinese       0.6             0.3          0.5     0.375\n",
       "5   Vietnamese  0.514749        0.257375          0.5  0.339825\n",
       "6         Thai  0.599824        0.299912          0.5  0.374931\n",
       "7      Finnish  0.828947        0.414474          0.5  0.453237\n",
       "8       Basque  0.804878        0.402439          0.5  0.445946\n",
       "9       Korean  0.586445        0.293223          0.5   0.36966\n",
       "10      Arabic  0.824155        0.412077          0.5  0.451801\n",
       "11      Hebrew  0.705607        0.352804          0.5  0.413699"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines = pd.DataFrame(np.array(baselines), columns=[\"Language\", \"Accuracy\", \"Macro_Precision\", \"Macro_Recall\", \"Macro_F1\"])\n",
    "baselines.iloc[:, 1:] = baselines.iloc[:, 1:].astype(float)\n",
    "baselines = utils.order_table(baselines)\n",
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_baselines_path = \"../results/balanced_length/baselines_sentiment_balanced_length.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(sentiment_baselines_path) as writer:\n",
    "    for metric in baselines.columns[1:]:\n",
    "        baselines[[\"Language\", metric]].rename(columns={metric: \"Baseline\"}).to_excel(writer, index=False, sheet_name=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
